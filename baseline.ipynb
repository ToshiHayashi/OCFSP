{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6867ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.datasets import fetch_datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import precision_score,accuracy_score,roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "def makefile(what,filename):\n",
    "    with open(filename,\"wb\") as f3:\n",
    "        pickle.dump(what,f3)\n",
    "\n",
    "def readfile(filename):\n",
    "    with open(filename,\"rb\") as f4:\n",
    "        ans=pickle.load(f4)\n",
    "    return ans\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3825cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.mixture import GaussianMixture\n",
    "OCSVM=OneClassSVM()\n",
    "LOF=LocalOutlierFactor(novelty=True)\n",
    "IF=IsolationForest()\n",
    "GMM=GaussianMixture(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4728a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_dataset=fetch_datasets()\n",
    "data_name=[]\n",
    "for word in fetch_dataset:\n",
    "    data_name.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split=[0.2,0.4,0.9]\n",
    "minor_result=[]\n",
    "major_result=[]\n",
    "both_result=[]\n",
    "for word in data_name:\n",
    "\n",
    "    print(word)\n",
    "    X=fetch_dataset[word][\"data\"]\n",
    "    Y=fetch_dataset[word][\"target\"]\n",
    "    #print(word,\":\",len(X[Y==1]),\":\",len(X[Y==-1]),\":\",len(X[0]))\n",
    "    X=(X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))\n",
    "    X[pd.isnull(X)]=0\n",
    "    random.seed(0)\n",
    "    d=len(X[0])\n",
    "    minor_line=[]\n",
    "    major_line=[]\n",
    "    both_line=[]\n",
    "    for split in test_split:\n",
    "        minor_score=[]\n",
    "        major_score=[]\n",
    "        result=[]\n",
    "        for random_value in range(5):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=split, random_state=random_value,stratify=Y)\n",
    "            positive=X_train[y_train==1]\n",
    "            negative=X_train[y_train==-1]\n",
    "            try:\n",
    "                OCSVM.fit(positive)\n",
    "                value1=OCSVM.score_samples(X_test)\n",
    "                minor_score.append(roc_auc_score(y_test,value1))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                OCSVM.fit(negative)\n",
    "                value2=OCSVM.score_samples(X_test)            \n",
    "                major_score.append(roc_auc_score(y_test,-value2))\n",
    "            except:\n",
    "                pass\n",
    "            final_score=value1-value2\n",
    "            result.append(roc_auc_score(y_test,final_score))\n",
    "        minor_line.append(np.array([np.array(minor_score).mean(),np.array(minor_score).std()]))\n",
    "        major_line.append(np.array([np.array(major_score).mean(),np.array(major_score).std()]))\n",
    "        both_line.append(np.array([np.array(result).mean(),np.array(result).std()]))\n",
    "    minor_result.append(minor_line)\n",
    "    major_result.append(major_line)\n",
    "    both_result.append(both_line)\n",
    "    \n",
    "makefile(minor_result,\"OCSVMmin_5AUC.pkl\")\n",
    "makefile(major_result,\"OCSVMmaj_5AUC.pkl\")\n",
    "makefile(both_result,\"OCSVMensemble_5AUC.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split=[0.2,0.4,0.9]\n",
    "minor_result=[]\n",
    "major_result=[]\n",
    "both_result=[]\n",
    "for word in data_name:\n",
    "\n",
    "    print(word)\n",
    "    X=fetch_dataset[word][\"data\"]\n",
    "    Y=fetch_dataset[word][\"target\"]\n",
    "    #print(word,\":\",len(X[Y==1]),\":\",len(X[Y==-1]),\":\",len(X[0]))\n",
    "    X=(X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))\n",
    "    X[pd.isnull(X)]=0\n",
    "    random.seed(0)\n",
    "    d=len(X[0])\n",
    "    minor_line=[]\n",
    "    major_line=[]\n",
    "    both_line=[]\n",
    "    for split in test_split:\n",
    "        minor_score=[]\n",
    "        major_score=[]\n",
    "        result=[]\n",
    "        for random_value in range(5):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=split, random_state=random_value,stratify=Y)\n",
    "            positive=X_train[y_train==1]\n",
    "            negative=X_train[y_train==-1]\n",
    "            try:\n",
    "                LOF.fit(positive)\n",
    "                value1=LOF.score_samples(X_test)\n",
    "                minor_score.append(roc_auc_score(y_test,value1))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                LOF.fit(negative)\n",
    "                value2=LOF.score_samples(X_test)            \n",
    "                major_score.append(roc_auc_score(y_test,-value2))\n",
    "            except:\n",
    "                pass\n",
    "            final_score=value1-value2\n",
    "            result.append(roc_auc_score(y_test,final_score))\n",
    "        minor_line.append(np.array([np.array(minor_score).mean(),np.array(minor_score).std()]))\n",
    "        major_line.append(np.array([np.array(major_score).mean(),np.array(major_score).std()]))\n",
    "        both_line.append(np.array([np.array(result).mean(),np.array(result).std()]))\n",
    "    minor_result.append(minor_line)\n",
    "    major_result.append(major_line)\n",
    "    both_result.append(both_line)\n",
    "makefile(minor_result,\"LOFmin_5AUC.pkl\")\n",
    "makefile(major_result,\"LOFmaj_5AUC.pkl\")\n",
    "makefile(both_result,\"LOFensemble_5AUC.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2dcc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split=[0.2,0.4,0.9]\n",
    "minor_result=[]\n",
    "major_result=[]\n",
    "both_result=[]\n",
    "for word in data_name:\n",
    "\n",
    "    print(word)\n",
    "    X=fetch_dataset[word][\"data\"]\n",
    "    Y=fetch_dataset[word][\"target\"]\n",
    "    #print(word,\":\",len(X[Y==1]),\":\",len(X[Y==-1]),\":\",len(X[0]))\n",
    "    X=(X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))\n",
    "    X[pd.isnull(X)]=0\n",
    "    random.seed(0)\n",
    "    d=len(X[0])\n",
    "    minor_line=[]\n",
    "    major_line=[]\n",
    "    both_line=[]\n",
    "    for split in test_split:\n",
    "        minor_score=[]\n",
    "        major_score=[]\n",
    "        result=[]\n",
    "        for random_value in range(5):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=split, random_state=random_value,stratify=Y)\n",
    "            positive=X_train[y_train==1]\n",
    "            negative=X_train[y_train==-1]\n",
    "            try:\n",
    "                IF.fit(positive)\n",
    "                value1=IF.score_samples(X_test)\n",
    "                minor_score.append(roc_auc_score(y_test,value1))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                IF.fit(negative)\n",
    "                value2=IF.score_samples(X_test)            \n",
    "                major_score.append(roc_auc_score(y_test,-value2))\n",
    "            except:\n",
    "                pass\n",
    "            final_score=value1-value2\n",
    "            result.append(roc_auc_score(y_test,final_score))\n",
    "        minor_line.append(np.array([np.array(minor_score).mean(),np.array(minor_score).std()]))\n",
    "        major_line.append(np.array([np.array(major_score).mean(),np.array(major_score).std()]))\n",
    "        both_line.append(np.array([np.array(result).mean(),np.array(result).std()]))\n",
    "    minor_result.append(minor_line)\n",
    "    major_result.append(major_line)\n",
    "    both_result.append(both_line)\n",
    "makefile(minor_result,\"IFmin_5AUC.pkl\")\n",
    "makefile(major_result,\"IFmaj_5AUC.pkl\")\n",
    "makefile(both_result,\"IFensemble_5AUC.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c6f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split=[0.2,0.4,0.9]\n",
    "minor_result=[]\n",
    "major_result=[]\n",
    "both_result=[]\n",
    "for word in data_name:\n",
    "\n",
    "    print(word)\n",
    "    X=fetch_dataset[word][\"data\"]\n",
    "    Y=fetch_dataset[word][\"target\"]\n",
    "    #print(word,\":\",len(X[Y==1]),\":\",len(X[Y==-1]),\":\",len(X[0]))\n",
    "    X=(X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))\n",
    "    X[pd.isnull(X)]=0\n",
    "    random.seed(0)\n",
    "    d=len(X[0])\n",
    "    minor_line=[]\n",
    "    major_line=[]\n",
    "    both_line=[]\n",
    "    for split in test_split:\n",
    "        minor_score=[]\n",
    "        major_score=[]\n",
    "        result=[]\n",
    "        for random_value in range(5):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=split, random_state=random_value,stratify=Y)\n",
    "            positive=X_train[y_train==1]\n",
    "            negative=X_train[y_train==-1]\n",
    "            try:\n",
    "                GMM.fit(positive)\n",
    "                value1=GMM.score_samples(X_test)\n",
    "                minor_score.append(roc_auc_score(y_test,value1))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                GMM.fit(negative)\n",
    "                value2=GMM.score_samples(X_test)            \n",
    "                major_score.append(roc_auc_score(-y_test,value2))\n",
    "            except:\n",
    "                pass\n",
    "            final_score=value1-value2\n",
    "            result.append(roc_auc_score(y_test,final_score))\n",
    "        minor_line.append(np.array([np.array(minor_score).mean(),np.array(minor_score).std()]))\n",
    "        major_line.append(np.array([np.array(major_score).mean(),np.array(major_score).std()]))\n",
    "        both_line.append(np.array([np.array(result).mean(),np.array(result).std()]))\n",
    "    minor_result.append(minor_line)\n",
    "    major_result.append(major_line)\n",
    "    both_result.append(both_line)\n",
    "makefile(minor_result,\"GMMmin_5AUC.pkl\")\n",
    "makefile(major_result,\"GMMmaj_5AUC.pkl\")\n",
    "makefile(both_result,\"GMMensemble_5AUC.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
