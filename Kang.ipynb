{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd51e499",
   "metadata": {},
   "source": [
    "https://www.sciencedirect.com/science/article/pii/S0957417421012744"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510016f1",
   "metadata": {},
   "source": [
    "clustering, annotated as cluster, one vs rest binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dcd7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.datasets import fetch_datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_name=[]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import precision_score,accuracy_score,roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "def makefile(what,filename):\n",
    "    with open(filename,\"wb\") as f3:\n",
    "        pickle.dump(what,f3)\n",
    "\n",
    "def readfile(filename):\n",
    "    with open(filename,\"rb\") as f4:\n",
    "        ans=pickle.load(f4)\n",
    "    return ans\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a0b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_dataset=fetch_datasets()\n",
    "data_name=[]\n",
    "for word in fetch_dataset:\n",
    "    data_name.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93f27e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53788f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44593cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=LogisticRegression(C=1000)\n",
    "RF=RandomForestClassifier()\n",
    "MLP=MLPClassifier(activation=\"tanh\",solver=\"lbfgs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0195bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed18cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36b8c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster=20\n",
    "Clustering=KMeans(n_clusters=n_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e38b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split=[0.2,0.4,0.9]\n",
    "minor_result=[]\n",
    "major_result=[]\n",
    "both_result=[]\n",
    "for word in data_name:\n",
    "    \n",
    "    print(word)\n",
    "    X=fetch_dataset[word][\"data\"]\n",
    "    Y=fetch_dataset[word][\"target\"]\n",
    "    #print(word,\":\",len(X[Y==1]),\":\",len(X[Y==-1]),\":\",len(X[0]))\n",
    "    X=(X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))\n",
    "    X[pd.isnull(X)]=0\n",
    "    random.seed(0)\n",
    "    d=len(X[0])\n",
    "\n",
    "    minor_table=[]\n",
    "    major_table=[]\n",
    "    both_table=[]\n",
    "\n",
    "    for split in test_split:\n",
    "        minor_score=[]\n",
    "        major_score=[]\n",
    "        result=[]\n",
    "        for random_value in range(5):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=split, random_state=random_value,stratify=Y)\n",
    "            positive=X_train[y_train==1]\n",
    "            negative=X_train[y_train==-1]\n",
    "            value1=0\n",
    "            try:\n",
    "                Cluster=Clustering.fit_predict(positive)\n",
    "\n",
    "                Self_label=np.zeros([n_cluster,len(Cluster)])\n",
    "            \n",
    "                for n in range(n_cluster):\n",
    "                    Self_label[n][Cluster==n]=1\n",
    "                    RF.fit(positive,Self_label[n])\n",
    "                    value1+=RF.predict_proba(X_test).T[0]\n",
    "                minor_score.append(roc_auc_score(y_test,value1))\n",
    "            except:\n",
    "                minor_score.append(-1)\n",
    "\n",
    "            value2=0\n",
    "            try:\n",
    "                Cluster=Clustering.fit_predict(negative)\n",
    "                Self_label=np.zeros([n_cluster,len(Cluster)])\n",
    "                \n",
    "                for n in range(n_cluster):\n",
    "                    Self_label[n][Cluster==n]=1\n",
    "                    RF.fit(negative,Self_label[n])\n",
    "                    value2+=RF.predict_proba(X_test).T[0]\n",
    "\n",
    "                major_score.append(roc_auc_score(y_test,-value2))\n",
    "            except:\n",
    "                major_score.append(-1)\n",
    "            #print(len(LR.predict_log_proba(X_test).T))\n",
    "            try:\n",
    "                final_score=value1-value2\n",
    "                result.append(roc_auc_score(y_test,final_score))\n",
    "            except:\n",
    "                result.append(-1)\n",
    "        minor_table.append(np.array([np.array(minor_score).mean(),np.array(minor_score).std()]))\n",
    "        major_table.append(np.array([np.array(major_score).mean(),np.array(major_score).std()]))\n",
    "        both_table.append(np.array([np.array(result).mean(),np.array(result).std()]))\n",
    "    minor_result.append(minor_table)\n",
    "    major_result.append(major_table)\n",
    "    both_result.append(both_table)\n",
    "makefile(minor_result,\"Seokho_minor_RF.pkl\")\n",
    "makefile(major_result,\"Seokho_major_RF.pkl\")\n",
    "makefile(both_result,\"Seokho_both_RF.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c19981",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split=[0,2,0.4,0.9]\n",
    "minor_result=[]\n",
    "major_result=[]\n",
    "both_result=[]\n",
    "for word in data_name:\n",
    "    \n",
    "    print(word)\n",
    "    X=fetch_dataset[word][\"data\"]\n",
    "    Y=fetch_dataset[word][\"target\"]\n",
    "    #print(word,\":\",len(X[Y==1]),\":\",len(X[Y==-1]),\":\",len(X[0]))\n",
    "    X=(X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))\n",
    "    X[pd.isnull(X)]=0\n",
    "    random.seed(0)\n",
    "    d=len(X[0])\n",
    "\n",
    "    minor_table=[]\n",
    "    major_table=[]\n",
    "    both_table=[]\n",
    "\n",
    "    for split in test_split:\n",
    "        minor_score=[]\n",
    "        major_score=[]\n",
    "        result=[]\n",
    "        for random_value in range(5):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=split, random_state=random_value,stratify=Y)\n",
    "            positive=X_train[y_train==1]\n",
    "            negative=X_train[y_train==-1]\n",
    "            value1=0\n",
    "            try:\n",
    "                Cluster=Clustering.fit_predict(positive)\n",
    "\n",
    "                Self_label=np.zeros([n_cluster,len(Cluster)])\n",
    "            \n",
    "                for n in range(n_cluster):\n",
    "                    Self_label[n][Cluster==n]=1\n",
    "                    LR.fit(positive,Self_label[n])\n",
    "                    value1+=LR.predict_proba(X_test).T[0]\n",
    "                minor_score.append(roc_auc_score(y_test,value1))\n",
    "            except:\n",
    "                minor_score.append(-1)\n",
    "\n",
    "            value2=0\n",
    "            try:\n",
    "                Cluster=Clustering.fit_predict(negative)\n",
    "                Self_label=np.zeros([n_cluster,len(Cluster)])\n",
    "                \n",
    "                for n in range(n_cluster):\n",
    "                    Self_label[n][Cluster==n]=1\n",
    "                    LR.fit(negative,Self_label[n])\n",
    "                    value2+=LR.predict_proba(X_test).T[0]\n",
    "\n",
    "                major_score.append(roc_auc_score(y_test,-value2))\n",
    "            except:\n",
    "                major_score.append(-1)\n",
    "            #print(len(LR.predict_log_proba(X_test).T))\n",
    "            try:\n",
    "                final_score=value1-value2\n",
    "                result.append(roc_auc_score(y_test,final_score))\n",
    "            except:\n",
    "                result.append(-1)\n",
    "        minor_table.append(np.array([np.array(minor_score).mean(),np.array(minor_score).std()]))\n",
    "        major_table.append(np.array([np.array(major_score).mean(),np.array(major_score).std()]))\n",
    "        both_table.append(np.array([np.array(result).mean(),np.array(result).std()]))\n",
    "    minor_result.append(minor_table)\n",
    "    major_result.append(major_table)\n",
    "    both_result.append(both_table)\n",
    "makefile(minor_result,\"Seokho_minor_LR.pkl\")\n",
    "makefile(major_result,\"Seokho_major_LR.pkl\")\n",
    "makefile(both_result,\"Seokho_both_LR.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c84d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split=[0,2,0.4,0.9]\n",
    "minor_result=[]\n",
    "major_result=[]\n",
    "both_result=[]\n",
    "for word in data_name:\n",
    "    \n",
    "    print(word)\n",
    "    X=fetch_dataset[word][\"data\"]\n",
    "    Y=fetch_dataset[word][\"target\"]\n",
    "    #print(word,\":\",len(X[Y==1]),\":\",len(X[Y==-1]),\":\",len(X[0]))\n",
    "    X=(X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))\n",
    "    X[pd.isnull(X)]=0\n",
    "    random.seed(0)\n",
    "    d=len(X[0])\n",
    "\n",
    "    minor_table=[]\n",
    "    major_table=[]\n",
    "    both_table=[]\n",
    "\n",
    "    for split in test_split:\n",
    "        minor_score=[]\n",
    "        major_score=[]\n",
    "        result=[]\n",
    "        for random_value in range(5):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=split, random_state=random_value,stratify=Y)\n",
    "            positive=X_train[y_train==1]\n",
    "            negative=X_train[y_train==-1]\n",
    "            value1=0\n",
    "            try:\n",
    "                Cluster=Clustering.fit_predict(positive)\n",
    "\n",
    "                Self_label=np.zeros([n_cluster,len(Cluster)])\n",
    "            \n",
    "                for n in range(n_cluster):\n",
    "                    Self_label[n][Cluster==n]=1\n",
    "                    MLP.fit(positive,Self_label[n])\n",
    "                    value1+=MLP.predict_proba(X_test).T[0]\n",
    "                minor_score.append(roc_auc_score(y_test,value1))\n",
    "            except:\n",
    "                minor_score.append(-1)\n",
    "\n",
    "            value2=0\n",
    "            try:\n",
    "                Cluster=Clustering.fit_predict(negative)\n",
    "                Self_label=np.zeros([n_cluster,len(Cluster)])\n",
    "                \n",
    "                for n in range(n_cluster):\n",
    "                    Self_label[n][Cluster==n]=1\n",
    "                    MLP.fit(negative,Self_label[n])\n",
    "                    value2+=MLP.predict_proba(X_test).T[0]\n",
    "\n",
    "                major_score.append(roc_auc_score(y_test,-value2))\n",
    "            except:\n",
    "                major_score.append(-1)\n",
    "            #print(len(LR.predict_log_proba(X_test).T))\n",
    "            try:\n",
    "                final_score=value1-value2\n",
    "                result.append(roc_auc_score(y_test,final_score))\n",
    "            except:\n",
    "                result.append(-1)\n",
    "        minor_table.append(np.array([np.array(minor_score).mean(),np.array(minor_score).std()]))\n",
    "        major_table.append(np.array([np.array(major_score).mean(),np.array(major_score).std()]))\n",
    "        both_table.append(np.array([np.array(result).mean(),np.array(result).std()]))\n",
    "    minor_result.append(minor_table)\n",
    "    major_result.append(major_table)\n",
    "    both_result.append(both_table)\n",
    "makefile(minor_result,\"Seokho_minor_MLP.pkl\")\n",
    "makefile(major_result,\"Seokho_major_MLP.pkl\")\n",
    "makefile(both_result,\"Seokho_both_MLP.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c330b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
